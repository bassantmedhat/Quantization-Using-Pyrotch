{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Drive if your data is on it"
      ],
      "metadata": {
        "id": "rkWuvx0yI--S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WVViUN6Pju-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce832eb1-34db-4b4b-8bb1-cf06021a6fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "colab_nb = 'google.colab' in str(get_ipython())\n",
        "if colab_nb:\n",
        "  from google.colab import drive\n",
        "  drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import sys\n",
        "sys.path.append(\"../../util\")\n",
        "\n",
        "# PyTorch quantization supports only CPU\n",
        "device = \"cpu\""
      ],
      "metadata": {
        "id": "-W8X6bV4pSMa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install these frameworks as they include modifications to enable model quantization\n",
        "\n",
        "!pip install git+https://github.com/bassantmedhat/gen-efficientnet-pytorch.git\n",
        "!pip install git+https://github.com/bassantmedhat/fastseg.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gbxnRjcyQ5PW",
        "outputId": "ad05bf04-5b49-46a5-e0d8-84c0351e4d06"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/bassantmedhat/gen-efficientnet-pytorch.git\n",
            "  Cloning https://github.com/bassantmedhat/gen-efficientnet-pytorch.git to /tmp/pip-req-build-i5a62a24\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/bassantmedhat/gen-efficientnet-pytorch.git /tmp/pip-req-build-i5a62a24\n",
            "  Resolved https://github.com/bassantmedhat/gen-efficientnet-pytorch.git to commit 1e6f13a2f1ed5a741a1ce16e18e43e5ff30676a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from geffnet==1.0.2) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from geffnet==1.0.2) (0.18.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->geffnet==1.0.2) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->geffnet==1.0.2) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->geffnet==1.0.2) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->geffnet==1.0.2) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->geffnet==1.0.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->geffnet==1.0.2) (1.3.0)\n",
            "Collecting git+https://github.com/bassantmedhat/fastseg.git\n",
            "  Cloning https://github.com/bassantmedhat/fastseg.git to /tmp/pip-req-build-v2n5uozx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/bassantmedhat/fastseg.git /tmp/pip-req-build-v2n5uozx\n",
            "  Resolved https://github.com/bassantmedhat/fastseg.git to commit cf92833e55f90bdb29c1741b92171d7342ec306b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: geffnet>=0.9.8 in /usr/local/lib/python3.10/dist-packages (from fastseg==0.1.2) (1.0.2)\n",
            "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from fastseg==0.1.2) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from fastseg==0.1.2) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from fastseg==0.1.2) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from fastseg==0.1.2) (0.18.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->fastseg==0.1.2) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.5.0->fastseg==0.1.2) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->fastseg==0.1.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->fastseg==0.1.2) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvkQcD-IWnZB"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FbEt-xVUj58U"
      },
      "outputs": [],
      "source": [
        "from fastseg import MobileV3Small\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MobileV3SmallWithSoftmax(nn.Module):\n",
        "    def __init__(self, num_classes=3, use_aspp=True, num_filters=64):\n",
        "        super(MobileV3SmallWithSoftmax, self).__init__()\n",
        "        # Initialize the base MobileV3Small model\n",
        "        self.model = MobileV3Small(num_classes=num_classes, use_aspp=use_aspp, num_filters=num_filters)\n",
        "\n",
        "        # Define a Softmax layer for the final output\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the base model\n",
        "        x = self.model(x)\n",
        "\n",
        "        # Apply Softmax to the output\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# load pretrained model to perform Quantization\n",
        "model = MobileV3SmallWithSoftmax(num_classes=3, use_aspp=True, num_filters=64)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/final_TRAINED_model.pth',map_location = \"cpu\"))\n",
        "model = model.to(device)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Kx5IIKVagRyW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building Training & Testing Pipeline\n"
      ],
      "metadata": {
        "id": "-PSEVCwPpJN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some other usefuls libs\n",
        "\n",
        "from fastai.vision.all import *\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "\n",
        "own_data = True\n",
        "path = \"/content/drive/MyDrive/lane_Data/\"\n",
        "\n",
        "def get_image_array_from_fn(fn):\n",
        "    image = cv2.imread(fn)\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n"
      ],
      "metadata": {
        "id": "vgLe_9pVpH0F"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sys import platform\n",
        "folder_token = \"\\\\\" if platform == \"win32\" else \"/\"\n",
        "fnames = get_image_files(path+\"train/\")"
      ],
      "metadata": {
        "id": "Z0j_EMPXNQVC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_func(fn): return path+\"train_label\"+f\"/{fn.stem}_label{fn.suffix}\"\n",
        "codes = np.array(['back', 'left','right'],dtype=str)"
      ],
      "metadata": {
        "id": "qc4v3xK9M4Ur"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls = SegmentationDataLoaders.from_label_func(\n",
        "    path, bs=8, fnames = fnames, label_func = label_func, codes = codes\n",
        ")\n",
        "learn = Learner(dls,  model, metrics=[DiceMulti(), foreground_acc])"
      ],
      "metadata": {
        "id": "mC11OMjWNWMH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optional if you want to fine tune your pretarined model\n",
        "def train(learn,epochs):\n",
        "  learn.fine_tune(epochs)\n",
        "  model = learn.model"
      ],
      "metadata": {
        "id": "z2NVjHr-pkrk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train(learn,5)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JD2juej4dSA4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot a validation sample output from the original model to compare it with the output from the quantized model"
      ],
      "metadata": {
        "id": "-0Qp98ElNh5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an example image\n",
        "test_path = path+\"./test\"\n",
        "print(str((test_path)))\n",
        "img = cv2.imread(str(get_image_files(test_path)[1]))\n",
        "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "print(img.shape)\n",
        "print(str(get_image_files(test_path)[5]))\n",
        "plt.imshow(np.array(learn.predict(img)[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "collapsed": true,
        "id": "JWHQeY1irRGh",
        "outputId": "640834f6-cfb3-4546-ddcf-fe90c5c8c929"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/lane_Data/./test\n",
            "(89, 256, 3)\n",
            "/content/drive/MyDrive/lane_Data/test/resized_Town04_Clear_Noon_09_09_2020_14_57_22_frame_1172_validation_set.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>dice_multi</th>\n",
              "      <th>foreground_acc</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/metrics.py:373: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(binary_dice_scores)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d1330538be0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the model if you have fine-tuned it\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/final_TRAINED_model.pth')"
      ],
      "metadata": {
        "id": "j1lAq7auyUcE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIOiLD_1wUwd"
      },
      "source": [
        "## Post training static quantization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.ao.quantization\n",
        "\n",
        "class QuantizedMobileV3SmallWithSoftmax(nn.Module):\n",
        "    def __init__(self, num_classes=3, use_aspp=True, num_filters=64):\n",
        "        super(QuantizedMobileV3SmallWithSoftmax, self).__init__()\n",
        "        # Define quantization and dequantization stubs\n",
        "        self.quant = torch.ao.quantization.QuantStub()\n",
        "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
        "\n",
        "        # Define the main model\n",
        "        self.model = MobileV3Small(num_classes=num_classes, use_aspp=use_aspp, num_filters=num_filters)\n",
        "\n",
        "        # Define the softmax layer for the final output\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Quantize the input\n",
        "        x = self.quant(x)\n",
        "\n",
        "        # Pass through the main model\n",
        "        x = self.model(x)\n",
        "\n",
        "        # Dequantize the output\n",
        "        x = self.dequant(x)\n",
        "\n",
        "        # Apply softmax to the output\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "P64pd0mQFhSG",
        "collapsed": true
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JEOqzAFfw5ud"
      },
      "outputs": [],
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
        "    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n",
        "    os.remove('temp_delme.p')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the quantized model architecture\n",
        "net_quantized = QuantizedMobileV3SmallWithSoftmax().to(device)\n",
        "\n",
        "# Define the path to the pretrained model weights\n",
        "model_path = '/content/drive/MyDrive/final_TRAINED_model.pth'\n",
        "\n",
        "# Load the pretrained model weights\n",
        "state_dict = torch.load(model_path, map_location='cpu')\n",
        "\n",
        "# Load the state dictionary into the model with relaxed state dict checking\n",
        "net_quantized.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "net_quantized.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrKkBTQed6Oh",
        "outputId": "364a84b9-082a-4b14-b3db-0a813efba621",
        "collapsed": true
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedMobileV3SmallWithSoftmax(\n",
              "  (quant): QuantStub()\n",
              "  (dequant): DeQuantStub()\n",
              "  (model): MobileV3Small(\n",
              "    (trunk): MobileNetV3_Small(\n",
              "      (early): Sequential(\n",
              "        (0): Conv2dSame(\n",
              "          3, 16, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "          (quant): QuantStub()\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (1): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): HardSwishMe()\n",
              "      )\n",
              "      (block0): Sequential(\n",
              "        (0): DepthwiseSeparableConv(\n",
              "          (conv_dw): Conv2dSame(\n",
              "            16, 16, kernel_size=(3, 3), stride=(2, 2), groups=16, bias=False\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "          )\n",
              "          (bn1): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (block1): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(72, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv_dw): Conv2dSame(\n",
              "            72, 72, kernel_size=(3, 3), stride=(2, 2), groups=72, bias=False\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "          )\n",
              "          (bn2): BatchNorm2d(72, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): ReLU(inplace=True)\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): QuantStub()\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv_dw): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
              "          (bn2): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): ReLU(inplace=True)\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): QuantStub()\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "      )\n",
              "      (block2): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2dSame(\n",
              "            96, 96, kernel_size=(5, 5), stride=(1, 1), dilation=(2, 2), groups=96, bias=False\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "          )\n",
              "          (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (conv_pwl): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): QuantStub()\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=240, bias=False)\n",
              "          (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): QuantStub()\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=240, bias=False)\n",
              "          (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): QuantStub()\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "      )\n",
              "      (block3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=120, bias=False)\n",
              "          (bn2): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (conv_pwl): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): QuantStub()\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=144, bias=False)\n",
              "          (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (conv_pwl): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): QuantStub()\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "      )\n",
              "      (block4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2dSame(\n",
              "            288, 288, kernel_size=(5, 5), stride=(1, 1), dilation=(4, 4), groups=288, bias=False\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "          )\n",
              "          (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): QuantStub()\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(8, 8), dilation=(4, 4), groups=576, bias=False)\n",
              "          (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): QuantStub()\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(8, 8), dilation=(4, 4), groups=576, bias=False)\n",
              "          (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (quant): QuantStub()\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): QuantStub()\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "      )\n",
              "      (block5): Sequential(\n",
              "        (0): ConvBnAct(\n",
              "          (conv): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
              "          (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (aspp_conv1): Sequential(\n",
              "      (0): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (aspp_conv2): Sequential(\n",
              "      (0): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
              "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (aspp_conv3): Sequential(\n",
              "      (0): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36))\n",
              "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (aspp_pool): Sequential(\n",
              "      (0): AdaptiveAvgPool2d(output_size=1)\n",
              "      (1): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (convs2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (convs4): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (conv_up1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (conv_up2): ConvBnRelu(\n",
              "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv_up3): ConvBnRelu(\n",
              "      (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (last): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.ao.quantization import default_qconfig, prepare\n",
        "\n",
        "# Set quantization configuration for the model\n",
        "net_quantized.qconfig = default_qconfig\n",
        "\n",
        "# Disable quantization for specific parts of the model, if needed\n",
        "net_quantized.softmax.qconfig = None  # Disable quantization for the softmax layer\n",
        "\n",
        "# Insert observers for tracking statistics during calibration\n",
        "net_quantized = prepare(net_quantized)\n",
        "\n",
        "# Display the model with observers inserted\n",
        "net_quantized\n"
      ],
      "metadata": {
        "id": "VJ3QDLF_bbYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b8cba072-2cdf-4691-bf4d-4029da45e439"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedMobileV3SmallWithSoftmax(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (dequant): DeQuantStub()\n",
              "  (model): MobileV3Small(\n",
              "    (trunk): MobileNetV3_Small(\n",
              "      (early): Sequential(\n",
              "        (0): Conv2dSame(\n",
              "          3, 16, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "          (quant): QuantStub(\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (1): BatchNorm2d(\n",
              "          16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (2): HardSwishMe()\n",
              "      )\n",
              "      (block0): Sequential(\n",
              "        (0): DepthwiseSeparableConv(\n",
              "          (conv_dw): Conv2dSame(\n",
              "            16, 16, kernel_size=(3, 3), stride=(2, 2), groups=16, bias=False\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "          )\n",
              "          (bn1): BatchNorm2d(\n",
              "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(\n",
              "              16, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(\n",
              "              8, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "          )\n",
              "          (conv_pw): Conv2d(\n",
              "            16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn2): BatchNorm2d(\n",
              "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (block1): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(\n",
              "            16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn1): BatchNorm2d(\n",
              "            72, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv_dw): Conv2dSame(\n",
              "            72, 72, kernel_size=(3, 3), stride=(2, 2), groups=72, bias=False\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "          )\n",
              "          (bn2): BatchNorm2d(\n",
              "            72, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act2): ReLU(inplace=True)\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(\n",
              "            72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn3): BatchNorm2d(\n",
              "            24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (quant): QuantStub(\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(\n",
              "            24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn1): BatchNorm2d(\n",
              "            88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv_dw): Conv2d(\n",
              "            88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn2): BatchNorm2d(\n",
              "            88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act2): ReLU(inplace=True)\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(\n",
              "            88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn3): BatchNorm2d(\n",
              "            24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (quant): QuantStub(\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "      )\n",
              "      (block2): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(\n",
              "            24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn1): BatchNorm2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2dSame(\n",
              "            96, 96, kernel_size=(5, 5), stride=(1, 1), dilation=(2, 2), groups=96, bias=False\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "          )\n",
              "          (bn2): BatchNorm2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(\n",
              "              96, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(\n",
              "              24, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "          )\n",
              "          (conv_pwl): Conv2d(\n",
              "            96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn3): BatchNorm2d(\n",
              "            40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (quant): QuantStub(\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(\n",
              "            40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn1): BatchNorm2d(\n",
              "            240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2d(\n",
              "            240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=240, bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn2): BatchNorm2d(\n",
              "            240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(\n",
              "              240, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(\n",
              "              64, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "          )\n",
              "          (conv_pwl): Conv2d(\n",
              "            240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn3): BatchNorm2d(\n",
              "            40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (quant): QuantStub(\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(\n",
              "            40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn1): BatchNorm2d(\n",
              "            240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2d(\n",
              "            240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=240, bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn2): BatchNorm2d(\n",
              "            240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(\n",
              "              240, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(\n",
              "              64, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "          )\n",
              "          (conv_pwl): Conv2d(\n",
              "            240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn3): BatchNorm2d(\n",
              "            40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (quant): QuantStub(\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "      )\n",
              "      (block3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(\n",
              "            40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn1): BatchNorm2d(\n",
              "            120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2d(\n",
              "            120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=120, bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn2): BatchNorm2d(\n",
              "            120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(\n",
              "              120, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(\n",
              "              32, 120, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "          )\n",
              "          (conv_pwl): Conv2d(\n",
              "            120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn3): BatchNorm2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (quant): QuantStub(\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(\n",
              "            48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn1): BatchNorm2d(\n",
              "            144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2d(\n",
              "            144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=144, bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn2): BatchNorm2d(\n",
              "            144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(\n",
              "              144, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(\n",
              "              40, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "          )\n",
              "          (conv_pwl): Conv2d(\n",
              "            144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn3): BatchNorm2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (quant): QuantStub(\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "      )\n",
              "      (block4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(\n",
              "            48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn1): BatchNorm2d(\n",
              "            288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2dSame(\n",
              "            288, 288, kernel_size=(5, 5), stride=(1, 1), dilation=(4, 4), groups=288, bias=False\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "          )\n",
              "          (bn2): BatchNorm2d(\n",
              "            288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(\n",
              "              288, 72, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(\n",
              "              72, 288, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "          )\n",
              "          (conv_pwl): Conv2d(\n",
              "            288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn3): BatchNorm2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (quant): QuantStub(\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(\n",
              "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn1): BatchNorm2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2d(\n",
              "            576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(8, 8), dilation=(4, 4), groups=576, bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn2): BatchNorm2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(\n",
              "              576, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(\n",
              "              144, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "          )\n",
              "          (conv_pwl): Conv2d(\n",
              "            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn3): BatchNorm2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (quant): QuantStub(\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(\n",
              "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn1): BatchNorm2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2d(\n",
              "            576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(8, 8), dilation=(4, 4), groups=576, bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn2): BatchNorm2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(\n",
              "              576, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (quant): QuantStub(\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "            (dequant): DeQuantStub()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): Conv2d(\n",
              "              144, 576, kernel_size=(1, 1), stride=(1, 1)\n",
              "              (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "            )\n",
              "          )\n",
              "          (conv_pwl): Conv2d(\n",
              "            576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn3): BatchNorm2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (quant): QuantStub(\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (dequant): DeQuantStub()\n",
              "        )\n",
              "      )\n",
              "      (block5): Sequential(\n",
              "        (0): ConvBnAct(\n",
              "          (conv): Conv2d(\n",
              "            96, 576, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (bn1): BatchNorm2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "          (act1): HardSwishMe()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (aspp_conv1): Sequential(\n",
              "      (0): Conv2d(\n",
              "        576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (1): BatchNorm2d(\n",
              "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (aspp_conv2): Sequential(\n",
              "      (0): Conv2d(\n",
              "        576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (1): Conv2d(\n",
              "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12)\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (2): BatchNorm2d(\n",
              "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (aspp_conv3): Sequential(\n",
              "      (0): Conv2d(\n",
              "        576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (1): Conv2d(\n",
              "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36)\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (2): BatchNorm2d(\n",
              "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (aspp_pool): Sequential(\n",
              "      (0): AdaptiveAvgPool2d(output_size=1)\n",
              "      (1): Conv2d(\n",
              "        576, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (2): BatchNorm2d(\n",
              "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (convs2): Conv2d(\n",
              "      16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (convs4): Conv2d(\n",
              "      16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (conv_up1): Conv2d(\n",
              "      256, 64, kernel_size=(1, 1), stride=(1, 1)\n",
              "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "    (conv_up2): ConvBnRelu(\n",
              "      (conv): Conv2d(\n",
              "        128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn): BatchNorm2d(\n",
              "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv_up3): ConvBnRelu(\n",
              "      (conv): Conv2d(\n",
              "        96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn): BatchNorm2d(\n",
              "        64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (last): Conv2d(\n",
              "      64, 3, kernel_size=(1, 1), stride=(1, 1)\n",
              "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the test data loaders\n",
        "test_dls = SegmentationDataLoaders.from_label_func(\n",
        "    path + '/test/', bs=2, fnames=fnames, label_func=label_func, codes=codes, valid_pct=0\n",
        ")\n",
        "\n",
        "# Define the learner with the quantized model\n",
        "test_learn = Learner(\n",
        "    dls=test_dls,\n",
        "    model=net_quantized,\n",
        "    metrics=[DiceMulti(), foreground_acc]\n",
        ")"
      ],
      "metadata": {
        "id": "4628VGF4sEqi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_learn):\n",
        "    \"\"\"\n",
        "    Validate the model on test data loaders and extract metrics.\n",
        "\n",
        "    Args:\n",
        "        test_learn: Learner object containing the trained model and metrics.\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing the first test set's DiceMulti and foreground accuracy metrics.\n",
        "    \"\"\"\n",
        "    # Validate the model on each test data loader\n",
        "    test_results = [test_learn.validate(dl=dataloader) for dataloader in test_dls]\n",
        "\n",
        "    # Extract and store the metrics from the test results\n",
        "    test_metrics = [\n",
        "        (result[0], result[1])  # Assuming DiceMulti() metric is at index 0 and foreground_acc at index 1\n",
        "        for result in test_results\n",
        "    ]\n",
        "\n",
        "    # Get the first set of metrics (modify if you need metrics for all datasets)\n",
        "    dice_multi_metric, foreground_acc_metric = test_metrics[0]\n",
        "\n",
        "    # Display the test metrics\n",
        "    print(dice_multi_metric, foreground_acc_metric)\n",
        "\n",
        "    # Return the metrics for further use\n",
        "    return dice_multi_metric, foreground_acc_metric\n"
      ],
      "metadata": {
        "id": "4X_59cqRsXhY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CALIBRATE\n",
        "test(test_learn)"
      ],
      "metadata": {
        "id": "nWz3ZqUkbvbR",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "dd46308f-dd42-4f43-f1e2-ba1a248685e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
            "  warn(\"Your generator is empty.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5692243576049805 0.6263309888805252\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5692243576049805, 0.6263309888805252)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net_quantized = test_learn.model\n",
        "net_quantized =net_quantized.to(\"cpu\")"
      ],
      "metadata": {
        "id": "bp52zCPywTQb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_quantized = torch.ao.quantization.convert(net_quantized)"
      ],
      "metadata": {
        "id": "ezzss6V3bvhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5da21100-f159-46e9-f86c-1ad1d3848a83",
        "collapsed": true
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/utils.py:339: UserWarning: must run observer before calling calculate_qparams. Returning default values.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Check statistics of the various layers')\n",
        "net_quantized"
      ],
      "metadata": {
        "id": "PlbsHxILbveV",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d671bc5-166f-42f7-db40-bf7b50b38403"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check statistics of the various layers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedMobileV3SmallWithSoftmax(\n",
              "  (quant): Quantize(scale=tensor([0.0075]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "  (dequant): DeQuantize()\n",
              "  (model): MobileV3Small(\n",
              "    (trunk): MobileNetV3_Small(\n",
              "      (early): Sequential(\n",
              "        (0): Conv2dSame(\n",
              "          3, 16, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "          (quant): Quantize(scale=tensor([0.0767]), zero_point=tensor([64]), dtype=torch.quint8)\n",
              "          (dequant): DeQuantize()\n",
              "        )\n",
              "        (1): QuantizedBatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): HardSwishMe()\n",
              "      )\n",
              "      (block0): Sequential(\n",
              "        (0): DepthwiseSeparableConv(\n",
              "          (conv_dw): Conv2dSame(\n",
              "            16, 16, kernel_size=(3, 3), stride=(2, 2), groups=16, bias=False\n",
              "            (quant): Quantize(scale=tensor([4.0414]), zero_point=tensor([43]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "          )\n",
              "          (bn1): QuantizedBatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): QuantizedConv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), scale=0.11478430032730103, zero_point=20)\n",
              "            (quant): Quantize(scale=tensor([0.6943]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): QuantizedConv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), scale=0.03067821078002453, zero_point=0)\n",
              "          )\n",
              "          (conv_pw): QuantizedConv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), scale=3.0845563411712646, zero_point=43, bias=False)\n",
              "          (bn2): QuantizedBatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (block1): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): QuantizedConv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), scale=6.009283065795898, zero_point=66, bias=False)\n",
              "          (bn1): QuantizedBatchNorm2d(72, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv_dw): Conv2dSame(\n",
              "            72, 72, kernel_size=(3, 3), stride=(2, 2), groups=72, bias=False\n",
              "            (quant): Quantize(scale=tensor([22.8708]), zero_point=tensor([54]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "          )\n",
              "          (bn2): QuantizedBatchNorm2d(72, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): ReLU(inplace=True)\n",
              "          (se): Identity()\n",
              "          (conv_pwl): QuantizedConv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), scale=2.6857106685638428, zero_point=66, bias=False)\n",
              "          (bn3): QuantizedBatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "          (dequant): DeQuantize()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): QuantizedConv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), scale=5.354039192199707, zero_point=64, bias=False)\n",
              "          (bn1): QuantizedBatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): ReLU(inplace=True)\n",
              "          (conv_dw): QuantizedConv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), scale=5.841922760009766, zero_point=79, padding=(1, 1), groups=88, bias=False)\n",
              "          (bn2): QuantizedBatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): ReLU(inplace=True)\n",
              "          (se): Identity()\n",
              "          (conv_pwl): QuantizedConv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), scale=1.742167353630066, zero_point=60, bias=False)\n",
              "          (bn3): QuantizedBatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): Quantize(scale=tensor([2.0746]), zero_point=tensor([61]), dtype=torch.quint8)\n",
              "          (dequant): DeQuantize()\n",
              "        )\n",
              "      )\n",
              "      (block2): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): QuantizedConv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), scale=3.6220924854278564, zero_point=60, bias=False)\n",
              "          (bn1): QuantizedBatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2dSame(\n",
              "            96, 96, kernel_size=(5, 5), stride=(1, 1), dilation=(2, 2), groups=96, bias=False\n",
              "            (quant): Quantize(scale=tensor([4.9498]), zero_point=tensor([80]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "          )\n",
              "          (bn2): QuantizedBatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): QuantizedConv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), scale=0.04401994124054909, zero_point=42)\n",
              "            (quant): Quantize(scale=tensor([0.1916]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): QuantizedConv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.047599464654922485, zero_point=57)\n",
              "          )\n",
              "          (conv_pwl): QuantizedConv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), scale=0.4805110692977905, zero_point=71, bias=False)\n",
              "          (bn3): QuantizedBatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "          (dequant): DeQuantize()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): QuantizedConv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), scale=1.7693098783493042, zero_point=77, bias=False)\n",
              "          (bn1): QuantizedBatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): QuantizedConv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), scale=2.0210165977478027, zero_point=81, padding=(4, 4), dilation=(2, 2), groups=240, bias=False)\n",
              "          (bn2): QuantizedBatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): QuantizedConv2d(240, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.0983649268746376, zero_point=70)\n",
              "            (quant): Quantize(scale=tensor([0.0384]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): QuantizedConv2d(64, 240, kernel_size=(1, 1), stride=(1, 1), scale=0.09273194521665573, zero_point=76)\n",
              "          )\n",
              "          (conv_pwl): QuantizedConv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), scale=0.05711750313639641, zero_point=72, bias=False)\n",
              "          (bn3): QuantizedBatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): Quantize(scale=tensor([1.0580]), zero_point=tensor([63]), dtype=torch.quint8)\n",
              "          (dequant): DeQuantize()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): QuantizedConv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), scale=1.6014430522918701, zero_point=62, bias=False)\n",
              "          (bn1): QuantizedBatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): QuantizedConv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), scale=1.6962602138519287, zero_point=71, padding=(4, 4), dilation=(2, 2), groups=240, bias=False)\n",
              "          (bn2): QuantizedBatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): QuantizedConv2d(240, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.04577241837978363, zero_point=78)\n",
              "            (quant): Quantize(scale=tensor([0.0491]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): QuantizedConv2d(64, 240, kernel_size=(1, 1), stride=(1, 1), scale=0.05405966565012932, zero_point=71)\n",
              "          )\n",
              "          (conv_pwl): QuantizedConv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), scale=0.046873219311237335, zero_point=57, bias=False)\n",
              "          (bn3): QuantizedBatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): Quantize(scale=tensor([1.6382]), zero_point=tensor([56]), dtype=torch.quint8)\n",
              "          (dequant): DeQuantize()\n",
              "        )\n",
              "      )\n",
              "      (block3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): QuantizedConv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), scale=3.473356246948242, zero_point=78, bias=False)\n",
              "          (bn1): QuantizedBatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): QuantizedConv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), scale=3.8737709522247314, zero_point=41, padding=(4, 4), dilation=(2, 2), groups=120, bias=False)\n",
              "          (bn2): QuantizedBatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): QuantizedConv2d(120, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.004302693996578455, zero_point=127)\n",
              "            (quant): Quantize(scale=tensor([0.1224]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): QuantizedConv2d(32, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.0394112803041935, zero_point=50)\n",
              "          )\n",
              "          (conv_pwl): QuantizedConv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), scale=0.3170683681964874, zero_point=66, bias=False)\n",
              "          (bn3): QuantizedBatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "          (dequant): DeQuantize()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): QuantizedConv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), scale=1.1166117191314697, zero_point=65, bias=False)\n",
              "          (bn1): QuantizedBatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): QuantizedConv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), scale=3.35967755317688, zero_point=58, padding=(4, 4), dilation=(2, 2), groups=144, bias=False)\n",
              "          (bn2): QuantizedBatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): QuantizedConv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), scale=0.05615903064608574, zero_point=39)\n",
              "            (quant): Quantize(scale=tensor([0.0612]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): QuantizedConv2d(40, 144, kernel_size=(1, 1), stride=(1, 1), scale=0.07370535284280777, zero_point=77)\n",
              "          )\n",
              "          (conv_pwl): QuantizedConv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), scale=0.04577404633164406, zero_point=60, bias=False)\n",
              "          (bn3): QuantizedBatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): Quantize(scale=tensor([0.8084]), zero_point=tensor([69]), dtype=torch.quint8)\n",
              "          (dequant): DeQuantize()\n",
              "        )\n",
              "      )\n",
              "      (block4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): QuantizedConv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), scale=1.9388114213943481, zero_point=64, bias=False)\n",
              "          (bn1): QuantizedBatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): Conv2dSame(\n",
              "            288, 288, kernel_size=(5, 5), stride=(1, 1), dilation=(4, 4), groups=288, bias=False\n",
              "            (quant): Quantize(scale=tensor([2.0975]), zero_point=tensor([73]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "          )\n",
              "          (bn2): QuantizedBatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): QuantizedConv2d(288, 72, kernel_size=(1, 1), stride=(1, 1), scale=0.13640038669109344, zero_point=55)\n",
              "            (quant): Quantize(scale=tensor([0.0550]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): QuantizedConv2d(72, 288, kernel_size=(1, 1), stride=(1, 1), scale=0.10905101895332336, zero_point=62)\n",
              "          )\n",
              "          (conv_pwl): QuantizedConv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.07992500066757202, zero_point=64, bias=False)\n",
              "          (bn3): QuantizedBatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "          (dequant): DeQuantize()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): QuantizedConv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), scale=0.4737289249897003, zero_point=50, bias=False)\n",
              "          (bn1): QuantizedBatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): QuantizedConv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), scale=0.7174432277679443, zero_point=77, padding=(8, 8), dilation=(4, 4), groups=576, bias=False)\n",
              "          (bn2): QuantizedBatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): QuantizedConv2d(576, 144, kernel_size=(1, 1), stride=(1, 1), scale=0.06972893327474594, zero_point=75)\n",
              "            (quant): Quantize(scale=tensor([0.0152]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): QuantizedConv2d(144, 576, kernel_size=(1, 1), stride=(1, 1), scale=0.05845153331756592, zero_point=87)\n",
              "          )\n",
              "          (conv_pwl): QuantizedConv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.013392890803515911, zero_point=61, bias=False)\n",
              "          (bn3): QuantizedBatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): Quantize(scale=tensor([0.3229]), zero_point=tensor([61]), dtype=torch.quint8)\n",
              "          (dequant): DeQuantize()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): QuantizedConv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), scale=0.5271859169006348, zero_point=58, bias=False)\n",
              "          (bn1): QuantizedBatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "          (conv_dw): QuantizedConv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), scale=1.1925474405288696, zero_point=94, padding=(8, 8), dilation=(4, 4), groups=576, bias=False)\n",
              "          (bn2): QuantizedBatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act2): HardSwishMe()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): QuantizedConv2d(576, 144, kernel_size=(1, 1), stride=(1, 1), scale=0.09156620502471924, zero_point=67)\n",
              "            (quant): Quantize(scale=tensor([0.0766]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "            (dequant): DeQuantize()\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv_expand): QuantizedConv2d(144, 576, kernel_size=(1, 1), stride=(1, 1), scale=0.09409085661172867, zero_point=60)\n",
              "          )\n",
              "          (conv_pwl): QuantizedConv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), scale=0.08019321411848068, zero_point=62, bias=False)\n",
              "          (bn3): QuantizedBatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (quant): Quantize(scale=tensor([0.6478]), zero_point=tensor([65]), dtype=torch.quint8)\n",
              "          (dequant): DeQuantize()\n",
              "        )\n",
              "      )\n",
              "      (block5): Sequential(\n",
              "        (0): ConvBnAct(\n",
              "          (conv): QuantizedConv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), scale=0.9211907386779785, zero_point=67, dilation=(4, 4), bias=False)\n",
              "          (bn1): QuantizedBatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (act1): HardSwishMe()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (aspp_conv1): Sequential(\n",
              "      (0): QuantizedConv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.12632519006729126, zero_point=62, bias=False)\n",
              "      (1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (aspp_conv2): Sequential(\n",
              "      (0): QuantizedConv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.1741020232439041, zero_point=58, bias=False)\n",
              "      (1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.07675706595182419, zero_point=72, padding=(12, 12), dilation=(12, 12))\n",
              "      (2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (aspp_conv3): Sequential(\n",
              "      (0): QuantizedConv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.1469748616218567, zero_point=64, bias=False)\n",
              "      (1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.053983256220817566, zero_point=59, padding=(36, 36), dilation=(36, 36))\n",
              "      (2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (aspp_pool): Sequential(\n",
              "      (0): AdaptiveAvgPool2d(output_size=1)\n",
              "      (1): QuantizedConv2d(576, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.014100096188485622, zero_point=76, bias=False)\n",
              "      (2): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (convs2): QuantizedConv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.14664976298809052, zero_point=77, bias=False)\n",
              "    (convs4): QuantizedConv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), scale=1.3780272006988525, zero_point=60, bias=False)\n",
              "    (conv_up1): QuantizedConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.09030824154615402, zero_point=60)\n",
              "    (conv_up2): ConvBnRelu(\n",
              "      (conv): QuantizedConv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.5890452265739441, zero_point=74, bias=False)\n",
              "      (bn): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv_up3): ConvBnRelu(\n",
              "      (conv): QuantizedConv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.07089045643806458, zero_point=66, bias=False)\n",
              "      (bn): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (last): QuantizedConv2d(64, 3, kernel_size=(1, 1), stride=(1, 1), scale=0.8875876665115356, zero_point=61)\n",
              "  )\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print_size_of_model(model)\n",
        "print_size_of_model(net_quantized)"
      ],
      "metadata": {
        "id": "rcdaXyOIcAN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a21313-ee40-4165-f3db-d640e4557800",
        "collapsed": true
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (KB): 1490.708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an example image\n",
        "test_path = path+\"./test\"\n",
        "print(str((test_path)))\n",
        "img = cv2.imread(str(get_image_files(test_path)[1]))\n",
        "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "print(img.shape)\n",
        "print(str(get_image_files(test_path)[5]))\n",
        "plt.imshow(np.array(test_learn.predict(img)[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "collapsed": true,
        "id": "RTsdj2tUsmwy",
        "outputId": "5b51b0bf-aeff-4b51-f812-f19c059a6ae2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/lane_Data/./test\n",
            "(89, 256, 3)\n",
            "/content/drive/MyDrive/lane_Data/test/resized_Town04_Clear_Noon_09_09_2020_14_57_22_frame_1172_validation_set.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d132cf97d90>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Quantizied Model"
      ],
      "metadata": {
        "id": "PFiVUESaQNRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net_quantized.state_dict(), '/content/drive/MyDrive/final_quantized_model_2.pth')"
      ],
      "metadata": {
        "id": "KoAfWRwjtL7r"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load and test Quantizied model\n"
      ],
      "metadata": {
        "id": "WBMl-03BJWYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.ao.quantization import default_qconfig, prepare, convert\n",
        "\n",
        "# 1. Initialize quantized model\n",
        "net_quantized = QuantizedMobileV3SmallWithSoftmax().to(device)\n",
        "net_quantized.qconfig = default_qconfig\n",
        "net_quantized.softmax.qconfig = None  # Disable quantization for softmax\n",
        "\n",
        "# 2. Insert observers\n",
        "net_quantized = prepare(net_quantized)\n",
        "\n",
        "# 3. Apply quantization\n",
        "net_quantized = convert(net_quantized)\n",
        "\n",
        "# 4. Load trained quantized model\n",
        "model_path = '/content/drive/MyDrive/final_quantized_model_2.pth'\n",
        "state_dict = torch.load(model_path, map_location='cpu')\n",
        "net_quantized.load_state_dict(state_dict, strict=False)\n",
        "net_quantized.eval()\n",
        "\n",
        "# Define test data loaders\n",
        "test_dls = SegmentationDataLoaders.from_label_func(\n",
        "    path + '/test/', bs=2, fnames=fnames, label_func=label_func, codes=codes, valid_pct=0\n",
        ")\n",
        "\n",
        "# Create Learner object for testing\n",
        "test_learn = Learner(test_dls, net_quantized, metrics=[DiceMulti(), foreground_acc])\n"
      ],
      "metadata": {
        "id": "6KiBtDYZJToW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnNnT-_C6JZD"
      },
      "source": [
        "# PREDICT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an example image\n",
        "test_path = path+\"./test\"\n",
        "print(str((test_path)))\n",
        "img = cv2.imread(str(get_image_files(test_path)[1]))\n",
        "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "print(img.shape)\n",
        "print(str(get_image_files(test_path)[5]))\n",
        "plt.imshow(np.array(test_learn.predict(img)[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "kYNI3shZJoW5",
        "outputId": "6cd1ffe4-78bf-44fc-91a6-4b081cd51ae3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/lane_Data/./test\n",
            "(89, 256, 3)\n",
            "/content/drive/MyDrive/lane_Data/test/resized_Town04_Clear_Noon_09_09_2020_14_57_22_frame_1172_validation_set.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d132d00e620>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict using non quantized model\n",
        "# Test with a sample\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/lane_Data/val/resized_Town04_Clear_Noon_09_09_2020_14_57_22_frame_0.png')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_tensor = transforms.ToTensor()(img)\n",
        "img_tensor = img_tensor.unsqueeze(0)\n",
        "image = img_tensor.to('cpu')\n",
        "print(\"Original image shape:\", image.shape)\n",
        "\n",
        "\n",
        "output = net_quantized(image)\n",
        "\n",
        "\n",
        "output_channel_1 = output[0][1].cpu().detach().numpy()\n",
        "output_channel_2 = output[0][2].cpu().detach().numpy()\n",
        "\n",
        "concatenated_output = output_channel_1 + output_channel_2\n",
        "plt.imshow(100*concatenated_output, cmap='gray')\n"
      ],
      "metadata": {
        "id": "kyrWD0_3frEs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "a1f6989f-15d1-47b0-c996-4bb41ae745b7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image shape: torch.Size([1, 3, 89, 256])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d132cc78190>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAADcCAYAAACmhHFpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHuklEQVR4nO3deXRb5Zk/8K/2fbFsWV7jPbYTJ3FIQghLSRuXQJkWGtoBSmeA9pTTkFAgQEvaA/zoFobOaSm0tNNlCtNTUkhboFACTQMJm7OS1cGO7XiLbUmWbe279P7+SO9bybETO5EtyX4+59yTWPdKeu+90r2P3uV5RYwxBkIIIYSQGSZOdwEIIYQQMjdREEIIIYSQtKAghBBCCCFpQUEIIYQQQtKCghBCCCGEpAUFIYQQQghJCwpCCCGEEJIWFIQQQgghJC0oCCGEEEJIWlAQQgghhJC0mLYg5Oc//znKy8uhVCqxcuVK7Nu3b7reihBCCCFZaFqCkBdffBGbNm3CY489ho8++ghLlizB2rVrYbfbp+PtCCGEEJKFRNMxgd3KlSuxYsUK/OxnPwMAxONxlJaW4p577sHDDz98zufG43EMDAxAp9NBJBKlumiEEEIImQaMMXg8HhQVFUEsnlwdhzTVhQiHwzh48CA2b97MHxOLxWhqakJzc/NZ24dCIYRCIf53f38/FixYkOpiEUIIIWQG9PX1oaSkZFLbprw5xuFwIBaLwWKxJD1usVhgtVrP2n7Lli0wGAx8oQCEEEIIyV46nW7S26Z9dMzmzZvhcrn40tfXl+4iETLniESipGWqzxWLxXw533ZSqRRSacorYQkhGWIq15CUXwny8vIgkUhgs9mSHrfZbCgoKDhre4VCAYVCkepiEEISCMGBcHGIx+P8b5FIBIlEwrdljCEej4MxxpdzSQwqGGOIRCL89ce+h0QigVqtRjweh9vt5u9zMRIveNPQxS3pfcYGWZM9RoSQ8aU8CJHL5Vi2bBl27tyJG2+8EcCZC97OnTuxcePGVL8dIXOacAM+141YCABEIhFfp1AoIBaL+b9isZi/RjQaRTAYRCwWQzQaPetGK/xfCC70ej20Wi1kMhmkUincbjfC4TBCoRDi8Ti/eWu1WiiVShQVFSEajaKtrQ3BYBCBQOCijsFMBgAUbBCSWtNSJ7pp0ybcfvvtWL58OS699FI89dRT8Pl8uPPOO6fj7QiZsxKbQcRiMQ8aEoMK4F9BRzgchkQiQW5uLjQaDQoKCs5qGvH5fLBarQiFQvD5fIhGo4hEInx9NBpFLBbj71lTU4OKigoUFxdDp9OhtbUVo6OjsFqtCAaDAM7UllRXVyM/Px/XXXcd3G43nn32WVitVvT19SXVnGQqqvEgJPWmJQi5+eabMTQ0hEcffRRWqxWNjY148803z+qsSgi5MEIthEwmg0wmSwo6YrEYr/kQmjtisRji8Ti/2UciEQSDQXi93qSmGAAIBoM80IjH47zGRPg7sfZFIpGgoKAAdXV1KCwshE6ng1gshtPphFarhcfjwejoKC9HJBKBx+OBz+dLqqEh00sqlfLjnFizJQRVQi0ZBVlkpk1LnpCL4Xa7YTAYzrlN4peJkEwznZ9PIfgQgg69Xg+NRsPXezweBINByOVyiEQihEIhxGIxHkAIr6FQKCCRSCbsjyUSiRCNRhEOh6FUKqHVannTSSQSQTQa5QHQgw8+iM997nO8dsVut8Pj8eDEiROw2+348MMPMTo6CpFIBKVSifnz5yMcDuPQoUMYGRnBqVOnEI1GU36syBlCU5gQbMbjcd5vJxqN8s+T8DddV8nFcrlc0Ov1k9o2K7uo05eEpJrQ4VD4bI39WzDRr8XxRpckdu5M3G6qn9/E15VKpZDJZEl/J9YkyGQy/p7jdS4V/o1Go3z9eDURQi1KLBbjtSbhcJgHM8Lrx2Ix/ppC2fR6PeRyOYqLi6FQKGAwGBAMBnk/E6/Xi1gsBpVKBbVaDYlEwmtpEvdVLBaftR9k6hhjvGZL+DvxPArHNRuaxEiysX3CsvEcZmUQMptRLc/ME5o1gDNNGcLNHUg+D4k33bGBhfCcxNETY0eJXEi5hH8lEgmkUinUanVSzcfYAEKlUkGpVMLlciEcDk/YsVTo4xEOh8/53sCZgEXoPDo2wInH47yGRKjNyMnJAQCo1Wo4nU4cOXIEoVCI5xAaGRmBWCyG0WgEACiVSn68xGIx31e5XM5rYxJvomRqGGPw+/3n3IaObXYaO7otEolk3b2DgpAMk20foEwlfDknCgKEJomqqirodDqUlJRALBbzjpQSiQROpxOnTp1CIBCA1+vlr5nYtCEQfl0mnr+xN/4L6fsw9jkSiYQ3jyQmBPJ6vbyPh3DTnuww2/N95saWPXGf4vE4+vv70dLSAoPBgNzcXH6c5HI5VCoVcnNzEQgEeNOP2WzmQZ7VakVLSwu/CcpkMmg0Gt7pVRhhIxxfMrcJn625XjMmfB/HjmzLxh+xFISQWWdsh8fxAhGRSASdTodrrrkGFRUVuPrqqyGVSuF0Ovn2ra2tePHFF2G329Hd3c2/2JFIJKkGIbF24FymcmGYKGCRyWRQq9UoKytDeXk5f7yvrw9DQ0Pwer3w+XyIRCJJVe5TLdN4zVDjbROLxdDS0oJQKITq6mpUVVXx9QqFgs8bpVAoEAwGIZVKUVlZCblcDgDo6OjA7t27eQdYtVoNi8XCmxD8fv+4QR+ZexJzzSQG2XPVeM2xQhNmNgXsFISQWScxj0Xi8FORSAS1Wg2lUoni4mJYLBYsWLAARUVF0Ov1fPIln8+H3t5e9PT08H4Mif0TxmYVTfWFcLyspcJ7h0IheL1eAIBWq+UdU4W+Fz6fD7FYDKOjozN2IbLb7WCM4b333oPb7UZOTg4UCgVEIhHC4TA6OjowNDSEQCAAtVqNhoYG3mmtuLgYy5Ytg9vthsvlQk5ODmpqahAKheB0OtHf38+bei6kPw2ZPRID/bkegAD/6uuTWDuUjcE6BSFkVhICEZlMxttLJRIJLBYLTCYTrr76apSUlOCyyy6DwWCATqdDKBSCSCSCy+VCc3MzhoeH4ff7EYlEkjpPAsk1FYk3x4u9UY6XlVPYn2g0yoOMWCwGrVaL8vJyFBUVwWQyYWhoCC6XC5FIBD6fjzctTbe+vj709/dDJBLh4MGDqKurg8lkgkqlQjQaxUcffQSHwwGfzwez2Yybb74Z+fn5AM4kN/z0pz8Nt9sNm80Gi8WClStXwul0oq+vD4cOHUJfXx8ikUhWVjWT1Er8Ds5liR3Msx0FIWTWYoxBq9VCq9ViyZIlMJvNKCkpgU6nQ3V1NYxGI0wmE8RiMex2OwYHB/Haa6/Bbrejra0Nfr+fZ/8UOnwJv8ASAwWJRMIThQkdWxPLMN7/x5M4KiTxOYkX3Wg0ilAoBIVCAbPZjPz8fBQUFEClUqGoqAgymQz19fXYvn07uru74fF4kjqrTdcNnDHGk5M5nU6oVCrI5XLE43H09PTwjpFqtZqPstFoNDCZTFi0aBFCoRA8Hg+0Wi0sFgsMBgP0ej1ycnJQXFwMr9cLt9uNU6dOoaurCyMjIylL+07IeJRKJVQqFe/s7XA44PF4UvJ5O9/3fC6hIITMSkIfA51OB7PZjBtuuAH19fUoKyuDWq3mCb6AM506BwYGcPToUfz2t7+F2+3mgYbQnDO2eSTxAiKXyyGTyRAIBM4KOibbiS4x90fia483jDIajUKpVKKgoABFRUUoKSlBSUkJGGOorq6Gy+VCb28vvF4vzxMy3Tdrxhj6+/vR39+ftE8A+IgXnU7H840IQ3T1ej2KioqSEq0J/W0qKiqwdOlSXHvttQgEAvD5fNi+fTv+/ve/4+TJk/D7/TRqhkwbjUaDnJwc5Ofnw2AwIBaLwefzXfR3KXEiR8Fc7vdEQQiZlcRiMWQyGZYuXYra2loUFRVBKpVi165d8Hg8cDgcCIfDfI4Tm80Gu92OYDCY1NFUaHMdT+JcK0LQImQWHTtaZipNCYkXo/EuTIwxtLS0YNu2baisrERpaSlvfgkGgwiFQjwYECaXS8fQvcQgLBaLIRgMYnR0FB9++CH6+/uxfPlynidE4Ha70dPTw0fJCCNshBwkCxcuhE6ng9VqhcPhwNGjR9HT08ObzoQkbEK6+fHOgfDZEP5WqVTIz88HYwyhUIjXykQiEYRCoRk9ZiTzCLVuHo8nJcF84rUl8bG5ioIQMitJJBLI5XIsWbIEK1euRGFhIeLxON5//320t7fj+PHjvBPqRBeWxF7mEyX0EjKLxuNxXiMydojsVPsyJAYeEz3nxIkT6OrqQllZGYqLi2Gz2eDxeM6qSRFu3onB1Exe8BI7CQtNNXv27MHg4CCKi4uh1WqTth8YGMDevXuhVquRn58PnU6HvLw85OTkIC8vD3V1dbjkkkvg9XoRCATw4osvYs+ePfy99Ho9pFIpYrEYr5kab8ZgpVLJa56MRiNqa2sRj8fh9Xp5mvlAIEBBCIHb7Ybf74ff70/ZdyfbRrBMJwpCyKyi1WqhVqvxqU99CrW1tbjqqqtQWFiIzs5O2Gw2HDt2DN3d3TyZ12R/2ZxvKKtwo0v89T3VX00T5fQY7zWE4asDAwNwOp0IBAIIh8NJN1phyKtarYbNZkMoFErbL67ExGYnT56E1WrFyMjIWZPneb1eDA4OQiqV8rZ4IUGbXq/HVVddhcsvv5ynIr/00ktRUFCA06dPw+12Q61WQywW846w3d3dCIVCMJlMUKvVqKyshFqthlarRSQSwdDQEPx+P4aHhxGNRqFWq3lZhWa5xF+uicnfyOwmdAIXpinIhk6gwpBd4YdIPB6HTCaDwWBAPB7nTZjCtSATPscUhJBZQyQS8XbcNWvWYPXq1cjNzYVYLMYHH3yA1tZWdHR0JPVbuBhjA5DEyd2E9ZPtmDrVC4JwUbTb7eOul8vlkMvlMBgMkMlkcDgck37t6cIYQzgcRk9PD0QiEY4fP560brwgTLigKhQKqFQqaLVaLF26FFqtFkqlEgsWLEBFRQVvjhHyjwhV6Pv374fP50NZWRlyc3Nx1VVXQa/XQ6fTwe/3o62tDb29vfj73/8OxhgP3oT3DQQCfESGcOFOTH9OZi+heTNbJGZtFpo4Y7EYlEolzGYzrw0NhUJndbRPJwpCyKyg0+mgVqtRX1+PkpIStLe3w2q1wm63w+v14tSpU3A6nRgdHU35eyf2fRj7eLrEYjGEQiG4XC5IpdKM+RU33iiAxGM33jGMx+N8RM3777+PYDCImpoalJaW8qRso6OjPGGaMORaoVBgxYoViEQi0Ol00Gg0MBgMUCgUPN+Kw+FAJBJBTU0NL1csFuO/Fv1+P5xOJ4aHh6HX66HX63kg6/P5eB+STDm+ZO5ijPGh7IlNr7FYDKdPn+aBtDDEX1ifbhSEkKwm/GJVq9XIyclBaWkpKisr0dnZiaGhIRw5cgR2u33Gep5nwpca+Fdve7/fD4lEclZK+XSaarAm5EiJRqNoa2uDw+HgNR1CAON2uxGNRlFUVASdTsdn+BXm2RGLxZDL5bwjrDDbsMfjQTQaRUFBwYRJ6AYHB9Hb24uSkhIUFxdDIpEgEolgeHg4KW9LphxfMneN189ECKgzFQUh5Lwydb4GkUiEBQsWYMGCBVi8eDGqq6ths9kwMjKC3t5edHR0wOl0pmxc//maU8Zun26MMQQCAT6HzmxI9iXkbfnggw/Q0tICmUzGO99KpVJ4vV4YDIaktP1SqRRlZWU8L4xcLh/3GJhMJtTV1fH29OHhYZw+fRpSqRQmkwm5ubnIzc1FXl4ePvWpT2FoaIhP0NfX14eenh64XK6M+54QkskoCCGTMp1pyi+EEBjl5+dj4cKFWLlyJRYtWoRdu3bBZrNheHgYAwMDKXmfxP9Pdt/HDgtNF2G23Avdj0yTOIRWJBJBpVJBoVDw5rhoNAqNRpMUhCgUCj4jr8fjgUqlAgCehE5oSpHL5bymAzhzDgcHB3nCO6PRCKPRiPLycmg0GthsNoyOjiIcDkMsFmNkZASBQIC3t08UjGTz8Sck1UQsw74NbrcbBoMh3cUgCRJrQoD0BSFC00vidO9GoxEGgwE5OTkwGAw8dfng4CDcbnfK3neiWoRzHYvx5n9Jl7FlOV9wlOm/5oVzklgTIuT/EDqWCqOEpFIp8vLyoFQqYTKZeAr+cDiMwcFB3lSXk5OD2tpaPkna0NAQ+vr6eGfVf/u3f8O1114Lo9EIrVYLn8+HQCCAlpYWDAwMoKurC8PDwzh06BCGh4d5LhqhvMIUAiqVCrFYDC6Xa0YSyREy01wuF58f6nyoJoRMSrovklKpFHK5nN9wgDMX9tHRUQwMDEz7TXM2/XpN7EUvDOkT9k/IbyIM983UfR6bQVaozRDKLxCCkuHh4aQpz4V99fl8/LW0Wi0GBgYgkUggk8ngcrlgs9n4Z27lypVQKBRQKBQ8z4hSqcS8efOg0Wig0+l4J1aJRIJAIMCbdoR+SzKZDFqtFqFQiNfECKNu5mrGTDK3URAyR1xMbUa6f8FLJBJccskluPXWW5GTkwOLxYK9e/dix44d6O3tRV9f37SW4Vw3iPP1s8iUvjSJzUMKhQILFy5EcXExPvOZz0Cv10OlUmF4eBgHDhxAV1cXdu3adVbG0Qs1Ua1LqjJPJh7fsbUKwmgBIUhJPF9jz6vf78fp06eTktAJwxmFTLTCSCixWIxwOAy/38+bgkpLS8EYw9KlS+FyufDGG2/wIdRqtRpXXnkl5HI5nE4nPB4PTp06haGhIRw+fBg+nw+jo6Pj1rSl+7NDyHSiIGSOGBuEZAOhClun06G0tBTLly+HyWRCXl4ebDYbNBoNrxWZbuP18cjWjp4SiQQGgwH5+flYsGABjEYjT4Vus9ngdruTag1SMTPweFJx3BKD6okSvU22lkGYG2Qs4bnBYBBerxcajYYPgQ4EAjw7r1arhUwmQ0FBAfx+P44fP877lxgMBixbtgxKpRKnT5/G6OgonyJAqVQiEonwWpPE4xWPx2nkDZnVKAiZI7KtqldoO29sbMT69euRl5eH3NxcfPjhh9i2bRsGBwfR19eHQCAwo+Uam3ws2wI7YcTMRx99hBMnTmD//v1J88uMjo7y/Bep6gM0ncdHGPUzE+fgnXfewcDAANasWYPly5fDarXC6XRCJpNBLpejqqqK92fz+Xw4deoUr6XLy8tDJBKBUqkEcGbkzSuvvILR0VGMjIwAOFNbolQqk/rECTM5C803k9nPC+lELvxIEY5ltl0vSPaiIIRkFLFYzEc8mEwmVFVVYfny5TzT3+DgIPbu3Zsx2QyncpHPlGBFSO4FnMmBAcz8KJ5UHouZOq42mw3hcBglJSXIy8vD4OAgnE4nlEolZDIZ1Go1QqFQ0hw0o6OjvEYvGo0iEonwdadPn+Z5SoSJ+nQ6HYqLi/l7ut1uKBQKeL1eeL1enkhtbLNTqjpBZ9LndCLZUEYyeRSEZKFsbQaYjLy8PFx33XWoqqrCddddB5PJhKKiInR0dGDXrl1oaWnhF+NskTiPQ6rPWapyuJyrT8tE7ymMVBpvhMdEzVbZ/Jn1eDwIBAL405/+hLfeeov3mRFG6JSWlkKr1fJ5a6xWK8LhMNRqNYLBIB8y/vvf/x6nT5+G1+vlc9EII72uuuoqrF+/HtFolDf/uFwudHZ2orOzE729vbBarbzGSjjuYzvdRiIRnm5+srUnQkdlofknU89VppaLXBgKQkjGkEql0Gq1qK6uRl1dHRYvXgzGGDweDxwOB+/IRymy0y+x+n68dePJ9puHEHTY7XbY7Xa+/1KpFBKJhAccdrsdwWCQD89ljMHr9WJgYADRaBTd3d38czz2mCiVShQUFCAWiyEYDMLn80Gv1yMYDPJJCoUMrYnBn0Kh4EOJgTNDJIUcKEIwMpHEvj9jz2u2nzOS+ShPCMkIMpkMFosFS5YswU9+8hPk5eXBYDDg2LFj+M1vfoPOzk4cOHAAgUAAXq833cWdlLEXdOFGkGFfuSlLnKVTyMY63nwwiWZ6n1OdXO9czVVCLYQwHDixFkJ4rkwmQ25uLhhjGBkZOWtWVmGSvmXLluHLX/4yr11JnDwvHA7zYb1Hjx5FT08Pf/68efOg1+uRl5cHkUiE9957D0NDQxgeHuajeBLPUeL/Eyc8S+wTQn1DyIWiPCEka8hkMhQVFUGj0cBisaCyshJmsxkajQZ+vx8OhwOtra04ffo0hoaG0l3cKRkvQVi2ByBjTabaPp0ByHjrUl0e4fUSaz6Ef4X/x2Ix3hwz3vsLgcbo6Cja29v5LMiJtS1SqRQKhQIajQZmsxmhUIg/XlFRAaPRyIMQq9XKk/iFw2EEg8Gk2hMhmHG73UnBceIosNn2WSWZiWpCSFqVlpbi2WefRXl5OfR6PZRKJfLy8uByuXD8+HG8//77eOKJJ5KqtzOdcBNMrC1IHEKaYV+5C5Lumo6JJPaNAJL74YxXKzUVic0WwPj7PLYGZqrHRRjqm5gRVi6Xw2w2w2KxoL6+HhUVFTz7an5+PgwGAwoLC/mQdZFIxCf0EyYuk8lkfPST3++HzWZDd3c3Xn75ZZ5gTeg4K+yHMDyYkKmimhCS0YQLrEqlgsFgQHl5OcrLy/nogs7OTjgcDrS0tKC7uxt+vz+r+4GkO939dBE6pk7UQTXT0pELQ6pT8fzzpfG/0PcJh8N8yG5iECKknx8eHobBYIDBYIBGo4FcLodCoeB5S4QgQqj5ELK0GgwGxONxaDQaeL1eHpCo1WqejE3I3iqcz3A4zEf7ZNJ5JLPLlIKQLVu24C9/+QtaW1uhUqlw+eWX47/+679QW1vLtwkGg3jggQfwxz/+EaFQCGvXrsWzzz4Li8WS8sKT7CRUKzc0NKC6uhpGoxFKpRLRaBQnT57Eww8/DKvVir6+PoRCoawLQBJvwrOR0IdAqVRCqVTyjKsulwuBQIAHI4FA4Kw06tPtfHlDprMsY3PIpILQeXVkZAShUAherxcnT55EYWEhTCYTHA4HTCYThoeH+ZD1WCyGrq4uxGIxXHbZZcjPz0djYyOUSiVPVy/MsaRSqfjInEgkAr/fD7lcDqVSCYfDgYGBAd4XhZDpMKUgZPfu3diwYQNWrFiBaDSKb3/727jmmmtw4sQJaDQaAMD999+Pv/3tb9i2bRsMBgM2btyIdevW4YMPPpiWHSCZT+jIWFxcDLVaDaPRCJVKhdraWhQXF0MqlcLn86GtrQ0nTpxAd3c3hoeHMTIyQr/AMpBKpYJGo0FJSQksFgu0Wi2USiU8Hg8PGqPRKNra2uB0OhEMBmc0EJmJz8xMfi7j8TgikQjPziqkog8GgxCJRHA4HHA4HDwIicfjOH36NGKxGIxGIxwOB5+7RqvVwuv1Ynh4GD6fD3K5HBqNhjeBx+NxyGQyKBQK2O126PV62Gw2WK1WHlwSkkoX1SdkaGgI+fn52L17Nz7xiU/A5XLBbDbjhRdewBe+8AUAQGtrK+rr69Hc3IzLLrvsvK9JfUJmH6lUCo1Gg/vvvx+LFy9GY2MjDAYDpNIzMTBjDG1tbfjKV76CgYEBeDye8w4rJOlTW1uL+fPn45ZbbsHatWt59b1wvoSJ4TZv3owDBw7g9OnTGZFYLhXG5j8Z298nla+fSDjGY2cPFt43MUAQ/gbAJ33Mzc2FXq9HY2MjD/qF1503bx5Wr16NnJwcFBYW8vcZGhrC4OAg/vznP+OVV16B1+ud8QzFJDvNWJ8Ql8sFADCZTACAgwcPIhKJoKmpiW9TV1eHefPmTRiEhEIh3nkKQMqmXyfpJ0w+19DQgMLCQtTW1qKsrAxmsxlarRYA4PV6sW/fPpw4cQI2mw1Op5NqPzJcMBiEy+Xiqd1VKhVPRw6c+TWtUqmwYMECPuJjtgQhY6W6o/FE/VbGDpcVakeExGITDf+ORCKQSCRgjCEYDKK7uzupNkUul0MsFqO1tRUGgwEOh4O/v9Pp5LUs4+U0ISQVLjgIicfjuO+++3DFFVegoaEBAGC1WiGXy2E0GpO2tVgssFqt477Oli1b8Pjjj19oMUgGk0gkUKvV2LRpE9asWQOj0ciTKgFnLphDQ0N46KGH0NnZCY/HQxe6LNDf3w+bzYbFixdj3rx5vFktcVSQSqXCf/7nf6KpqQmnTp3C6OhoUt6MRNl0zhM7nk5XTd3Y4zFeRtzE9z7f8YvFYvB4PPB4PHxW30QSiQSvvPIKJBJJ0oSQQop4YTgv1UyS6XDBQciGDRv4EMqLsXnzZmzatIn/7Xa7UVpaelGvSdJLqAFpbGxERUUFz2GQGIBEIhG0traio6ODt0/TRS47CL++Ozs78eGHH/KOqkJfH+DMZ0Cv1yMajeLKK6+E2WxGR0cHfD4fXC4X72x8vhEr2RSgTJdUHAPhNcbr5C0MzU1s8gGQNET3XGWQSqWQyWSoqamBWq3G6OgootEolEolRCIRH7EDnPns+P1+hMNhnqMk2zqek9S6oCBk48aNeP311/Huu++ipKSEP15QUIBwOAyn05lUG2Kz2VBQUDDuaykUCigUigspBslQUqkUSqUS3/jGN3DTTTclBR8Cj8eD3/72tzhx4gSv7iXZQehzsGPHDrzzzjv46le/ymeWFa4HYrEYRqMRer0e3/3ud+FwOPDUU0+hs7MT+/fvh8/nQywWmzDte+Kw5kwMTmdbcHQxfbA0Gg2MRiO+9rWvYf78+WhubobH40FBQQEkEgncbjcPZvx+P+943tLSwufHyebjSSnuL86UghDGGO655x68/PLL2LVrFyoqKpLWL1u2DDKZDDt37sRNN90EAGhra0Nvby9WrVqVulKTjGY0GpGTkwOFQoFwOIyjR4/C4XDweS+E+WA+/vhj9Pf3J/1SItlDmEvl5MmTUKlUcDqdSUPxg8Egn4jN7Xajq6uLz0Q7mdwTsyWx22wnDO09evQohoaG0NbWhkAggKGhIYjFYgQCAR7ghEIh2O32pJFUqU6xT7LLlEbH3H333XjhhRfw6quvJuUGMRgMvBp2/fr1eOONN/Dcc89Br9fjnnvuAQB8+OGHk3oPGh2T/RobG1FdXY1bbrkFCxYswBNPPIF9+/ZhaGiIJ1ESZvqkG830m+6LvJBiPD8/n3c4jsfjsNlsCAQCvAOlEHicqwzCcO5MrQEhE5NKpbyvTGIz20QJ3YRthMzCwmN03rPfVEbHTCkImajt9ne/+x3uuOMOAP9KVrZ169akZGUTNceMRUFI9hKq36+++mosWLCAZ9H861//ilOnTsHj8fAObhR8TL/E7J7ChX46jr0we6tOp+OjZOLxONxud1Lt12QJQQh9PrLPVOecEebFKSoqwuLFi3m/lKGhIVitVoyMjGB0dJQ+C1lm2oKQmUBBSPZauHAhqqqq8IUvfAHLly/Hd77zHWzfvp1Xv5OZM3Z6dmFOEaH2iVJxk0wgkUggl8uxZs0aPPTQQ3y49/79+7Fr1y4cPXoUx48fP2tyPbqeZDaaO4bMKJPJhJycHBgMBjDG0NzcjLa2NnR2dvKbHplZY6vD6aJNMpEwOkaYTE9Iwtbb24v29nY4HI6kZHDCPDpCDRvJflQTQi6KSCRCfX09amtr+QXl2LFj6O3tTXfRCM6e0VdANSEkG2k0GigUCvh8PoTDYfoMZyiqCSHTqqioCLW1tcjPz0dRUREKCwtRUFCAt99+G/v374fH40l3Eck/jZ1Mb7zEV5libAfFTCxjNidamw2EmlWxWAylUgmFQgGpVMpz1VgsFojFYnR3dyMQCCAYDCadIyF7LNUMZg4KQsiUlZaW4tprr8WSJUtw2WWX8XbdI0eOoKOjg3J+ZKDEEQmZaOwoiUyuqRH62dCNbOYJ2Vs1Gg3kcjlPBSBMurdkyRI+N05iWgDgX51g59K8VNmQw4SCEDJpwo1iYGAAb775Jg4dOoQdO3bwXyHvv//+jE/dTmaHsb9OM/WimenB3FzAGOM5RuLxOK8JkUqlCIfDfHRNYn4S4Xlz7QdSNnxOqU8ImRQhAJFKpXxOCUIIIWQs6hNCUsJkMmHZsmUoKipCY2Mjurq6sHv3bjgcDvT396e7eIQQQrIcBSFkXCKRCEajEcuXL8fixYtx00034b333sOpU6cQi8UoCCGEzErZ0I9iNqEghCSRSCTIycnBihUrUFRUhKqqKthsNjz00EPo7e3F0aNHafQLIWTWouBjZlEQQgCAp0uWy+UwGo1obGxEfn4+zGYz+vv78cILL8Dn88Hv96e7qIQQkrGoJmVqKAgh0Ol0WL16NYqKinDZZZchJycH5eXlcLvdOH78OAYGBuD1ehEOh9NdVJLBZuPFVxiOK5FIkubdmU37SC6eSCSCwWDgP+IAwG63IxwOIxgM0ojBc6AgZA4TiUSQy+XQ6XRYvHgxampqcMMNN0Cj0SAej6OrqwsOhwMjIyOUJpmc00STW2aiqQZLQi2h8JxMzmFC0kMkEkGhUEClUsFkMgE4M9JTGE481Yn95hIKQuYoqVSKnJwcbNiwAZWVlVi0aBHkcjk6OzvR19eHrVu3Ynh4GP39/XC73RTJk3PKhAuskIxKqL0Q8kKMrbmYSlkZY4jFYvzznwn7STJPPB6H0+mEx+OBy+UCAPj9fsRiMfrxdh4UhMwxQmIxrVYLs9mMK664ArW1tcjNzYXf78eePXvQ2tqK7du3UwdUkvGEgENI3y2TyZJqLXw+H6LRKL8RXEgQQc0vZDJCoRAAXFC/OSHrNHDmMx2NRscNoGcjCkLmEIlEgpqaGhQWFuKOO+5AZWUl6uvrodFo+MyVTz/9NLq6uqgDKskKOTk50Ov1+OIXv4jFixcD+NccNH6/H3/4wx/Q3d0Nq9XKbxKEZJoVK1Zg3bp1kEqlkEgk2LNnD/bv3w+HwwGn05nu4k0rCkLmCCHSLi4uRmVlJS6//HJUVVUhEAggHA7D5/PBbrfj2LFjsFqt6S4uIZMil8uh0WhQV1eHVatWQSwW8z4fHo8HH374IcLhMAKBAF/i8ThVkZOMIXRqra6uhkwmg0wmQ3d3N5RKJaTS2X+Lnv17SCASiVBTU4Pi4mKsX78e9fX1yM/Px8jICP73f/8XPT09aGlpwcjICIaHh9NdXEImzev18maXSCSC3NxcqFQqiMVi5Obm4t5774XL5UJ7ezsGBwfx6quvwuFwYGBggOY5IhmBMYZ9+/ahp6cHEokEIpEIo6OjGB0dnRMjEikImeW0Wi1UKhXKysowb9481NTUoLKyEm63G3a7HS0tLWhvb8ehQ4cQCATSXVxCpiQajSIUCiEWi4ExxmdTFZpkampqEAwGoVarkZ+fj6NHj0KhUPBaEa/XS4EISTsh6JiLKAiZxSQSCf7jP/4Dq1atQn19PfLy8mCxWBAKhfDEE0+gpaUFR48ehdfrRTAYTHdxSQoIHTUFs/0GK0ymKJVKefW18GtSJBJBqVRCoVCgrq4OVVVVqK2thd1ux65du9DZ2YkXX3yRgm8yawjffSEIF/4WrgOZeD2gIGSWkkgkkMlkMBqNyM/Ph1KpBADYbDa4XC60trbi448/xvDwMCKRSJpLO3tRfoDpJQyhHRkZQX9/P4LBIJRKJZ/12WQy8X4jAKDX62EymWC1WsEY4zN9BoNBOk9k1hGuP5l8HRKxDCuZ2+2GwWBIdzGyntlshsFgQG1tLfLy8tDW1sar+2KxGB8tIAwDI6k3GzOIZiKRSIT8/Hw+ykuoBdFqtfjWt77Fa0FUKhUPWrxeLzo6OvDUU0+hu7sbBw4cQCQSychfioRkG5fLxQP886GakFlE6GWt1WpRUlKCnJwchMNh9PT0oL29nTqdklmJMQabzXbW4zqdDq2trZDJZCguLuY1JFKpFAaDAWazGfPnz4dcLofT6YTT6cTg4OCcyM1ASKagmpBZQiqVQiqV4otf/CKamppQU1OD/Px8bN68GX/729945z0yPcZLW55hX605RywWIycnB6WlpXj++edRV1cHmUzGz1U0GoXb7YbP54PNZsO7776Lxx9/HIFAgJooCbkIVBMyh0gkEkilUj7jbW5uLkQiETweDxhjcLlclHiMzEnxeBzDw8MQi8U4fvw44vE4amtr+egZqVQKk8kErVYLpVKJqqoq1NXVwW63o7+/PyldOyFkelBNSBYTml9yc3Nx00034fOf/zx2796NgwcP8rwILpeLRr6QOU2oEamqqsLvfvc7lJeXQ6VSJfXZicfjGBkZQWtrK3bv3o2f/exn8Pl88Hq9aS49IdmHakJmMb1ej6KiIiiVSqjVauj1ehiNRtTX16OkpATxeBwDAwMYHBwct52ckOmQ2ByVYb9reI2IUqnE8ePHEQwG0dDQkDRXh0QigUajQWlpKWpqanDJJZegp6cHJ06cSHPpCZndKAjJIiKRCIsXL8bdd9+N0tJS1NXVQSKRQCwWQ6FQQCaTweVy4fDhwzRPBkmZyQYYwqiUTJ3q3uFw4Hvf+x4WLlyIZ555BmazOWm9SqVCaWkpTCYTVqxYgRdeeAGPPfYYNckQMo0oCMkSQsbH0tJSWCwWKBQKOJ1OuN1uPvSWMYauri6Ew2G6cJKUuZA8A5mYlyAajWJoaAg9PT3YvXs3TCYTJBIJ9Ho9ampqIJfLIZfLoVKpkJubi7KyMjQ0NGBoaIjnFSGEpBi7CFu2bGEA2L333ssfCwQC7O6772Ymk4lpNBq2bt06ZrVaJ/2aLpeLAaBlzDJ//nz2zW9+k/36179mH3/8Mdu+fTv74Q9/yG644Qam0+mYVqtlWq2WyWSytJeVlrm1iEQiJhaL+SISiZhIJEp7uSYqq0QiYRqNhhkMBlZcXMw+97nPsWPHjjGr1cri8TiLx+MsFoux1tZW9vvf/57ddtttTCaTMYlEkvby00JLNiwul2vS9/wLrgnZv38//ud//odPny24//778be//Q3btm2DwWDAxo0bsW7dOnzwwQcX+lZzklgshlKphMlkwqJFi1BeXo5FixahsLAQKpUKHo8Hx44dQ09PDzweT7qLS7JcqhOrpep1Uo39M1mZz+eDWCxGJBJBb28v3nnnHdTU1GD16tU89bvBYEBlZSUuvfRS+P1+hMNhhMNhnDx5Ej09PeneFUJmh0mHKwk8Hg+rqalhO3bsYFdffTWvCXE6nUwmk7Ft27bxbT/++GMGgDU3N4/7WsFgkLlcLr709fWlPYrLhEWhULDy8nJ26623soGBAebxeFgkEmGBQICNjIywp556islkMiYWi9NeVlqyexGLxUwmkzGpVHpBNRjj1YSke5+muv8KhYLdcMMNzGazMb/fzxhjvEYkFAoxv9/PBgcHWWtrK7vzzjuZRCLJuv2khZaZWqa9JmTDhg24/vrr0dTUhO9///v88YMHDyISiaCpqYk/VldXh3nz5qG5uRmXXXbZWa+1ZcsWPP744xdSjFlJLBZDpVLBYrHg05/+NBYuXAilUgm73Y4DBw4gHA4jGAzyY03IxWL/HKI6V8XjcYRCIfT09OAvf/kLn/ROINTq+P1++P1+dHd3U1ZVQlJkykHIH//4R3z00UfYv3//WeusVivkcjmMRmPS4xaLBVarddzX27x5MzZt2sT/drvdKC0tnWqxZg2pVAqz2YwlS5bg0UcfhV6vRzQaxb59+3DXXXchFAohHo/P6ZsGSS2hiWKqxs7Ym+2OHDmCjRs3TrhPQtCRqaN/CMlGUwpC+vr6cO+992LHjh18VtaLpVAokn51zFVqtRorVqyAyWRCTU0NKioqoNPpwBjD0NAQRkdHEYlEEIlE6AJI0koIPoSpAqLRaFIQk62fzwsNxgghF25KQcjBgwdht9txySWX8MdisRjeffdd/OxnP8Nbb72FcDgMp9OZVBtis9lQUFCQskLPRgaDAXfccQeqq6uxbNkyPtnW8PAwurq6MDg4iFgslrUXeJJ9JsoPIhKJeMdppVIJn89HNXOEkAsypSBkzZo1OHbsWNJjd955J+rq6vCtb30LpaWlkMlk2LlzJ2666SYAQFtbG3p7e7Fq1arUlXqWEIvF0Gg0WLNmDcrLyzF//nzk5OTAarVidHQUe/bswcjICE6fPo2uri76lUbSYmzgK/QhCYfDYIwhEolQEEIIuSBTCkJ0Oh0aGhqSHtNoNMjNzeWPf/WrX8WmTZtgMpmg1+txzz33YNWqVeN2Sp3rJBIJjEYj7rrrLtTX1yMvLw+hUAiHDx/G0aNH8dhjj9HwW5I2E9W6CZ0yg8EgQqEQ1c4RQi5YyjOm/uQnP4FYLMZNN92EUCiEtWvX4tlnn03122QtiUSChoYGmM1mnvejqqoKRqMRCoUCw8PDeO2113Dy5EmEw+F0F5dksEyYr2Um3zcTs7ASQi4OzaI7wxQKBb70pS+hoaEBt9xyC4qKipLWHzt2DJ/5zGcwMDBAVdxjnGskRoZ9jKfd2JEps3nIqLCfQhAyW/eTkNmCZtHNQBKJBJ/85CdRWVmJT3/60ygtLYVOp0MwGMThw4cxNDSEQ4cOobu7Gy6Xiy6046Bj8i/j9dOYrRL3bTbvJyFzEQUhM0QikeDKK6/E5ZdfjqVLl8JkMoExBo/Hg48++ghtbW34/e9/zyejI0RwrmaIuXRTnkv7SshcQUHIDCgtLYXZbMbChQtRV1cHjUaDSCSCgwcPoq+vD9u3b0dfXx/8fn+6izpnpXrulFSiAIQQMltREDKNhHwKFosF5eXlKCsrQ0lJCRhj8Pv9aGlpwccff4x9+/bBbrenu7hzWiZ08iTkXKhjLpmNKAiZBnK5HHK5HFdeeSXq6+thMpmg1WrR2dmJvr4+7Nu3D1arFZ2dnXA6nXC73eku8pxHnYBJpqMAhMxGFISkUGImSY1Gg8bGRqxevZondzp58iRsNhtefPFF9PT00EWFEELInEZBSApdccUVuPLKK1FWVobCwkJUVFTAbDbD5XLB4/Fg69atOHDgAIaGhigAIVklk/vMEEKyFwUhKSISiVBRUYHVq1ejtrYW5eXliEQiiEajCIfD8Pv96OvrQ2tra7qLSsiUCDlJKAAhhKQaBSEpoNFoYDAYUFNTg6VLl0KtViMWi+HXv/41duzYAb/fj1AohOPHj6e7qIRMGSUII4RMFwpCLoJMJoNSqYTRaERubi4sFgvMZjOi0SgCgQAOHz6MN954A9FolDo+EkIIIWNQEHKBxGIx1q5di40bN/IpzYuLiyESiXD48GEcP34c7e3tiEQi9CuSEEIIGQcFIVMgEokglUohk8mgVqtRXV2N1atXQyKRQCwWw+/3Y3h4GD09PWhtbcXo6CgFIIQQQsgEKAiZgpycHMyfPx+NjY1Yt24dSkpKIJPJ4PV64XK58NJLL2Hbtm18NIzT6Ux3kQkhhJCMRUHIOUilUhiNRkgkEkgkEpjNZlRVVaG+vh7Lly+HUqmESCSC2+1GT08PWlpasHfv3nQXm2QoGuZKCCHJKAg5h6qqKjz66KMwm80wm82Qy+VQqVTQaDTQ6/V82OLf//53/OhHP4LD4Uh3kUmGEYa3ikQiSCQSAEAsFuMJ7AghZC6jIGQccrkc+fn5qKysRENDAx/1IhaLAQB+vx+Dg4OIxWKIRqPo6OhAW1sb/cIlSRLnoyGEEHI2CkLGEIvFKC8vx09/+lOUlZWhoqICUqmUByAAsGfPHjz55JNwuVxwOBxwOp0UgJAJCXk2hJoP+qwQQsgZFIQkUCgUKCsrQ319PebPn4+CggIoFAr+izYejyMajWJkZATt7e1wOp0YGRlJc6lJpqOggxBCxkdByD/JZDKUlpbiN7/5DaqqqmA2myGVSpOq1IPBIIaGhjAwMID+/n5EIpE0lpjMtLHNKxRcEELIxZnzQYhYLIZcLsf8+fNRVVWFiooKWCwWxGIxuFwu9PT0IBaLAQDPA9Ld3Y1IJEIdC8k5McaoXwghhJzDnA5CRCIR1Go1ioqK8Mwzz6C+vh4mkwmxWAxWqxVHjhzBpk2b4Ha7AYC364dCIQpA5qALqfmg2hJCCJnYnAxCxGIxKisrYTQaYTAYUFBQgNLSUuTm5kIsFsPr9eLw4cM4evQorFYrvF5vuotMCCGEzDpzMghRqVR48MEHsXLlShQWFkKtVkOj0fARMH19ffjmN7+J06dPw+/3p7m0hBBCyOw0p4IQsViMuro6FBcXo7y8HHl5eVCpVIjFYtizZw/8fj/i8Ti6urrgcDjg8/nSXWRCCCFk1ppTQYhMJsP69euxevVqFBUVQalUYnh4GP39/bj33nvR2dmJSCSCWCyGYDCY7uISQgghs9qsD0IUCgVkMhkaGhpQWlqK+fPnIy8vD3K5HNFoFHv37kVHRwfsdjs8Hg+i0Wi6i0wIIYTMCbM+CDEYDMjJycGDDz6Iz3zmM5DL5RCLxYhGo3A4HHjqqadw8OBBhEIhGslACCGEzCDx+TdJ1t/fjy9/+cvIzc2FSqXCokWLcODAAb6eMYZHH30UhYWFUKlUaGpqQnt7e0oLPRnChGFmsxkVFRUAgKGhIbz99tt46aWXsHXrVvzpT3+C1WqlAIQQQghJgynVhIyOjuKKK67AJz/5SWzfvh1msxnt7e3Iycnh2zz55JN4+umn8fzzz6OiogKPPPII1q5dixMnTkCpVKZ8ByYiFoshlUpRXV2NxsZGBAIBHD58GM888wwOHToEn8/H+38QQgghZOaJ2BSqAB5++GF88MEHeO+998ZdzxhDUVERHnjgATz44IMAAJfLBYvFgueeew633HLLed/D7XbDYDBMtkgTWrhwISorK7Fw4UIUFxfziebeeust9PT0UMIxQgghZBq4XC7o9fpJbTul5pi//vWvWL58Ob74xS8iPz8fS5cuxa9//Wu+vqurC1arFU1NTfwxg8GAlStXorm5edzXDIVCcLvdScvFEolEWLVqFe666y5cccUVKCsrw759+/B///d/6OzsRCAQoACEEEIISbMpBSGnTp3CL37xC9TU1OCtt97C+vXr8Y1vfAPPP/88AMBqtQIALBZL0vMsFgtfN9aWLVtgMBj4UlpaeiH7wTU2NuKOO+7AihUrYDKZ0NbWhr/+9a/o6upCIBCg5hdCCCEkQ0ypT0g8Hsfy5cvxwx/+EACwdOlSHD9+HL/85S9x++23X1ABNm/ejE2bNvG/3W73BQciIpEIV199NTZs2ADgTPPQgQMHsG3bNsTjcep8SgghhGSQKQUhhYWFWLBgQdJj9fX1+POf/wwAKCgoAADYbDYUFhbybWw2GxobG8d9TYVCAYVCMZViAPjX7LcNDQ345Cc/CalUCqlUissuuwwmkwmHDh3Cxx9/jL6+PgpACCGEkAw0pSDkiiuuQFtbW9JjJ0+eRFlZGQCgoqICBQUF2LlzJw863G439u7di/Xr16emxP8klUqhVCqxYsUKbN68mQczIpEIIpEIXV1d2L59O3p7eykAIYQQQjLQlIKQ+++/H5dffjl++MMf4t///d+xb98+/OpXv8KvfvUrAGeaQ+677z58//vfR01NDR+iW1RUhBtvvPGiCiqTyaDT6VBYWIjly5fDaDSioKAAixcvhkqlwunTp3Hq1Cm+HD16FO3t7XA6nRf1voQQQgiZJmyKXnvtNdbQ0MAUCgWrq6tjv/rVr5LWx+Nx9sgjjzCLxcIUCgVbs2YNa2trm/Tru1wuBiBpEYvFTKPRsOrqavb5z3+evfrqq2zfvn1sZGSE+Xw+Fo/H2QcffMAee+wx9olPfOKs59NCCy200EILLTOzuFyuSd/zp5QnZCYIeUIkEgmMRiNKS0txyy23wGAwQKvVIi8vD3V1dVCr1TAYDBCJRBCLxdi6dSuefvppDAwMYGBgIN27QQghhMxJU8kTkrFzx8jlchiNRlRXV+POO+9ETk4OZDIZX88YQzweRzweRyQSQX9/f1L6eEIIIYRktowNQn7yk58gLy8Pubm50Ov1kEgkSevb2trw5ptvwm63o6+vDydOnEhTSQkhhBByITI2CLn55pthNBonXD84OIh//OMf6O7uRktLy8wVjBBCCCEpkbFBiFg8fjLXWCyGUCgEq9WKI0eOpCTNOyGEEEJmXsYGIYJ4PI5QKMT/jkQi8Pl8GB4exuDgIKVhJ4QQQrJUxgYh8Xgcfr8fJ0+exJYtW+DxePjjsVgMVquVJqEjhBBCsljGBiF+vx9erxe9vb3YsWMHRkdH010kQgghhKRQxgYhzz33HHbt2gWbzcZrQQghhBAye2RsENLS0oLm5mZ4vd50F4UQQggh02D8ISgZ4K233oLf7093MQghhBAyTTK2JmR4eDjdRSCEEELINMrYmhBCCCGEzG4UhBBCCCEkLSgIIYQQQkhaUBBCCCGEkLSgIIQQQgghaUFBCCGEEELSgoIQQgghhKQFBSGEEEIISQsKQgghhBCSFhSEEEIIISQtKAghhBBCSFpk7NwxhJAzRCJR0t+MsTSVhBBCUouCEEIymEgkglgs5v+Px+MUhBBCZg0KQgjJYIwxHnQk/p8QQmYDCkIIyXDxeDzdRSCEkGlBHVMJIYQQkhYUhBBCCCEkLaYUhMRiMTzyyCOoqKiASqVCVVUVvve97yW1UzPG8Oijj6KwsBAqlQpNTU1ob29PecEJIYQQkuXYFPzgBz9gubm57PXXX2ddXV1s27ZtTKvVsp/+9Kd8myeeeIIZDAb2yiuvsCNHjrDPfe5zrKKiggUCgUm9h8vlYgBooYUWWmihhZYsXFwu16TjiikFIddffz37yle+kvTYunXr2G233cYYYywej7OCggL2ox/9iK93Op1MoVCwrVu3Tuo9KAihhRZaaKGFluxdphKETKk55vLLL8fOnTtx8uRJAMCRI0fw/vvv47rrrgMAdHV1wWq1oqmpiT/HYDBg5cqVaG5uHvc1Q6EQ3G530kIIIYSQ2W9KQ3QffvhhuN1u1NXVQSKRIBaL4Qc/+AFuu+02AIDVagUAWCyWpOdZLBa+bqwtW7bg8ccfv5CyE0IIISSLTakm5KWXXsIf/vAHvPDCC/joo4/w/PPP47//+7/x/PPPX3ABNm/eDJfLxZe+vr4Lfi1CCCGEZI8p1YQ89NBDePjhh3HLLbcAABYtWoSenh5s2bIFt99+OwoKCgAANpsNhYWF/Hk2mw2NjY3jvqZCoYBCobjA4hNCCCEkW02pJsTv9/N5LAQSiYRndKyoqEBBQQF27tzJ17vdbuzduxerVq1KQXEJIYQQMltMqSbks5/9LH7wgx9g3rx5WLhwIQ4dOoQf//jH+MpXvgLgzARb9913H77//e+jpqYGFRUVeOSRR1BUVIQbb7xxOspPCCGEkGw16XE0jDG3283uvfdeNm/ePKZUKlllZSX7zne+w0KhEN8mHo+zRx55hFksFqZQKNiaNWtYW1vbpN+DhujSQgsttNBCS/YuUxmiK2Iss6bldLvdMBgM6S4GIYQQQi6Ay+WCXq+f1LY0dwwhhBBC0oKCEEIIIYSkBQUhhBBCCEkLCkIIIYQQkhYUhBBCCCEkLSgIIYQQQkhaUBBCCCGEkLSgIIQQQgghaZFxQUiG5U4jhBBCyBRM5T6ecUGIx+NJdxEIIYQQcoGmch/PuLTt8XgcbW1tWLBgAfr6+iad+pWkltvtRmlpKZ2DNKJzkH50DtKPzkH6TfYcMMbg8XhQVFQEsXhydRxTmkV3JojFYhQXFwMA9Ho9fejSjM5B+tE5SD86B+lH5yD9JnMOpjr3W8Y1xxBCCCFkbqAghBBCCCFpkZFBiEKhwGOPPQaFQpHuosxZdA7Sj85B+tE5SD86B+k3necg4zqmEkIIIWRuyMiaEEIIIYTMfhSEEEIIISQtKAghhBBCSFpQEEIIIYSQtKAghBBCCCFpkZFByM9//nOUl5dDqVRi5cqV2LdvX7qLNGv9v//3/yASiZKWuro6vj4YDGLDhg3Izc2FVqvFTTfdBJvNlsYSZ7d3330Xn/3sZ1FUVASRSIRXXnklaT1jDI8++igKCwuhUqnQ1NSE9vb2pG1GRkZw2223Qa/Xw2g04qtf/Sq8Xu8M7kV2O985uOOOO876Tlx77bVJ29A5uDhbtmzBihUroNPpkJ+fjxtvvBFtbW1J20zm2tPb24vrr78earUa+fn5eOihhxCNRmdyV7LWZM7B6tWrz/oufP3rX0/a5mLPQcYFIS+++CI2bdqExx57DB999BGWLFmCtWvXwm63p7tos9bChQsxODjIl/fff5+vu//++/Haa69h27Zt2L17NwYGBrBu3bo0lja7+Xw+LFmyBD//+c/HXf/kk0/i6aefxi9/+Uvs3bsXGo0Ga9euRTAY5NvcdtttaGlpwY4dO/D666/j3XffxV133TVTu5D1zncOAODaa69N+k5s3bo1aT2dg4uze/dubNiwAXv27MGOHTsQiURwzTXXwOfz8W3Od+2JxWK4/vrrEQ6H8eGHH+L555/Hc889h0cffTQdu5R1JnMOAOBrX/ta0nfhySef5OtScg5Yhrn00kvZhg0b+N+xWIwVFRWxLVu2pLFUs9djjz3GlixZMu46p9PJZDIZ27ZtG3/s448/ZgBYc3PzDJVw9gLAXn75Zf53PB5nBQUF7Ec/+hF/zOl0MoVCwbZu3coYY+zEiRMMANu/fz/fZvv27UwkErH+/v4ZK/tsMfYcMMbY7bffzm644YYJn0PnIPXsdjsDwHbv3s0Ym9y154033mBisZhZrVa+zS9+8Qum1+tZKBSa2R2YBcaeA8YYu/rqq9m999474XNScQ4yqiYkHA7j4MGDaGpq4o+JxWI0NTWhubk5jSWb3drb21FUVITKykrcdttt6O3tBQAcPHgQkUgk6XzU1dVh3rx5dD6mQVdXF6xWa9LxNhgMWLlyJT/ezc3NMBqNWL58Od+mqakJYrEYe/funfEyz1a7du1Cfn4+amtrsX79egwPD/N1dA5Sz+VyAQBMJhOAyV17mpubsWjRIlgsFr7N2rVr4Xa70dLSMoOlnx3GngPBH/7wB+Tl5aGhoQGbN2+G3+/n61JxDjJqFl2Hw4FYLJa0QwBgsVjQ2tqaplLNbitXrsRzzz2H2tpaDA4O4vHHH8dVV12F48ePw2q1Qi6Xw2g0Jj3HYrHAarWmp8CzmHBMx/v8C+usVivy8/OT1kulUphMJjonKXLttddi3bp1qKioQGdnJ7797W/juuuuQ3NzMyQSCZ2DFIvH47jvvvtwxRVXoKGhAQAmde2xWq3jfleEdWTyxjsHAPClL30JZWVlKCoqwtGjR/Gtb30LbW1t+Mtf/gIgNecgo4IQMvOuu+46/v/Fixdj5cqVKCsrw0svvQSVSpXGkhGSHrfccgv//6JFi7B48WJUVVVh165dWLNmTRpLNjtt2LABx48fT+qLRmbWROcgsZ/TokWLUFhYiDVr1qCzsxNVVVUpee+Mao7Jy8uDRCI5qwe0zWZDQUFBmko1txiNRsyfPx8dHR0oKChAOByG0+lM2obOx/QQjum5Pv8FBQVnddKORqMYGRmhczJNKisrkZeXh46ODgB0DlJp48aNeP311/HOO++gpKSEPz6Za09BQcG43xVhHZmcic7BeFauXAkASd+Fiz0HGRWEyOVyLFu2DDt37uSPxeNx7Ny5E6tWrUpjyeYOr9eLzs5OFBYWYtmyZZDJZEnno62tDb29vXQ+pkFFRQUKCgqSjrfb7cbevXv58V61ahWcTicOHjzIt3n77bcRj8f5BYKk1unTpzE8PIzCwkIAdA5SgTGGjRs34uWXX8bbb7+NioqKpPWTufasWrUKx44dSwoId+zYAb1ejwULFszMjmSx852D8Rw+fBgAkr4LF30OLrAj7bT54x//yBQKBXvuuefYiRMn2F133cWMRmNS71uSOg888ADbtWsX6+rqYh988AFrampieXl5zG63M8YY+/rXv87mzZvH3n77bXbgwAG2atUqtmrVqjSXOnt5PB526NAhdujQIQaA/fjHP2aHDh1iPT09jDHGnnjiCWY0Gtmrr77Kjh49ym644QZWUVHBAoEAf41rr72WLV26lO3du5e9//77rKamht16663p2qWsc65z4PF42IMPPsiam5tZV1cX+8c//sEuueQSVlNTw4LBIH8NOgcXZ/369cxgMLBdu3axwcFBvvj9fr7N+a490WiUNTQ0sGuuuYYdPnyYvfnmm8xsNrPNmzenY5eyzvnOQUdHB/vud7/LDhw4wLq6utirr77KKisr2Sc+8Qn+Gqk4BxkXhDDG2DPPPMPmzZvH5HI5u/TSS9mePXvSXaRZ6+abb2aFhYVMLpez4uJidvPNN7OOjg6+PhAIsLvvvpvl5OQwtVrNPv/5z7PBwcE0lji7vfPOOwzAWcvtt9/OGDszTPeRRx5hFouFKRQKtmbNGtbW1pb0GsPDw+zWW29lWq2W6fV6dueddzKPx5OGvclO5zoHfr+fXXPNNcxsNjOZTMbKysrY1772tbN+BNE5uDjjHX8A7He/+x3fZjLXnu7ubnbdddcxlUrF8vLy2AMPPMAikcgM7012Ot856O3tZZ/4xCeYyWRiCoWCVVdXs4ceeoi5XK6k17nYcyD6Z2EIIYQQQmZURvUJIYQQQsjcQUEIIYQQQtKCghBCCCGEpAUFIYQQQghJCwpCCCGEEJIWFIQQQgghJC0oCCGEEEJIWlAQQgghhJC0oCCEEEIIIWlBQQghhBBC0oKCEEIIIYSkxf8HpbWSw9RbIf8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export to ONNX"
      ],
      "metadata": {
        "id": "5Z6mDKlqfKU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "k-ewOaslDPxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "78e5c981-3990-4813-fab4-85ca493286ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.16.1\n"
          ]
        }
      ],
      "source": [
        "! pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "import geffnet\n",
        "import torch\n",
        "from fastseg import MobileV3Small\n",
        "\n",
        "\n",
        "geffnet.config.set_exportable(True)\n",
        "\n",
        "net_quantized.to(\"cpu\")\n",
        "net_quantized.eval()\n",
        "\n",
        "print('==> Exporting to ONNX')\n",
        "height, width = [256,89]\n",
        "print(f'Image dimensions: {height} x {width}')\n",
        "\n",
        "\n",
        "dummy_input = torch.randn(1, 3, height, width).to(\"cpu\")\n",
        "input_names = ['input0']\n",
        "output_names = ['output0']\n",
        "\n",
        "\n",
        "\n",
        "# Run model once, this is required by geffnet\n",
        "net_quantized(dummy_input)\n",
        "\n",
        "torch.onnx.export(net_quantized, dummy_input, \"/content/drive/MyDrive/final_QUanitzed_lane_seg_.onnx\", verbose=True,\n",
        "    input_names=input_names, output_names=output_names,\n",
        "    opset_version=11, keep_initializers_as_inputs=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ajNr2njoUq8y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}